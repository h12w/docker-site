<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Batch on Hai-Liang &#34;Hal&#34; Wang</title>
    <link>http://h12.io/tags/batch/</link>
    <description>Recent content in Batch on Hai-Liang &#34;Hal&#34; Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <copyright>Copyright (c) 2012-2018, Hǎi-Liàng &#34;Hal&#34; Wáng; all rights reserved.</copyright>
    <lastBuildDate>Sun, 22 Nov 2020 17:38:34 +0000</lastBuildDate>
    
	<atom:link href="http://h12.io/tags/batch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Go Patterns: Writer</title>
      <link>http://h12.io/article/go-patterns-buffered-writer/</link>
      <pubDate>Sun, 22 Nov 2020 17:38:34 +0000</pubDate>
      
      <guid>http://h12.io/article/go-patterns-buffered-writer/</guid>
      <description>A buffered writer is so ubiquitous that we do not usually consider it as a pattern, but sometimes we reinvent it or even do it in an inferior way. Let us look at a real use case first.
Batch processor What would you do to improve the throughput of a service? The answer is short: batching.
By processing and sending in a batch of multiple items instead of a single item at a time, you are amortizing the network overhead from the request-response round trip among all the items in the batch.</description>
    </item>
    
  </channel>
</rss>